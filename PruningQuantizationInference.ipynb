{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES USED\n",
    "#!pip install torch-summary\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "#import torch_pruning as tp\n",
    "import torchvision.models as models\n",
    "import caption\n",
    "import ResnetQuant as RQuant\n",
    "from torchsummary import summary\n",
    "import torch.quantization as quantization\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACROS\n",
    "img =\"img2.jpg\"\n",
    "word_map = \"WORDMAP_coco_5_cap_per_img_5_min_word_freq.json\"\n",
    "model = \"BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar\"\n",
    "beam_size = 5\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE FUNCTION\n",
    "def inference(encoder, decoder, img, word_map = word_map, beam_size = beam_size):\n",
    "    seq, alphas = caption.caption_image_beam_search(encoder, decoder, img, word_map, beam_size)\n",
    "    alphas = torch.FloatTensor(alphas)\n",
    "    words = [rev_word_map[ind] for ind in seq]\n",
    "    sentence = \"\"\n",
    "    for word in words:\n",
    "        sentence = sentence + \" \" + word\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUNE FUNCTION\n",
    "def prune_my_encoder(encoder):\n",
    "    for name, module in encoder.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            prune.ln_structured(module, name=\"weight\", amount=0.05, n=2, dim=0)\n",
    "            prune.remove(module, 'weight')\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            prune.ln_structured(module, name=\"weight\", amount=0.05, n=2, dim=0)\n",
    "            prune.remove(module, 'weight')\n",
    "    eps = 1e-3\n",
    "    with torch.no_grad():\n",
    "        for name, module in myencoder.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv2d):\n",
    "                module.weight[abs(module.weight)<eps] = 0\n",
    "            elif isinstance(module, torch.nn.Linear):\n",
    "                module.weight[abs(module.weight)<eps] = 0            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER CLASS\n",
    "class Encoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoded_image_size=14):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_image_size = encoded_image_size\n",
    "\n",
    "        #resnet = torchvision.models.resnet101(pretrained=True)  # pretrained ImageNet ResNet-101\n",
    "        resnet = models.resnet101()\n",
    "        #resnet = RQuant.resnet101()\n",
    "        #resnet.load_state_dict(torch.load(\"resnet101-2.pth\"))\n",
    "\n",
    "        # Remove linear and pool layers (since we're not doing classification)\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = torch.nn.Sequential(*modules)\n",
    "\n",
    "        # Resize image to fixed size to allow input images of variable size\n",
    "        self.adaptive_pool = torch.nn.AdaptiveAvgPool2d((encoded_image_size, encoded_image_size))\n",
    "\n",
    "        self.fine_tune()\n",
    "        #self.qconfig = quantization.get_default_qconfig('qnnpack')\n",
    "        # set the qengine to control weight packing\n",
    "        #torch.backends.quantized.engine = 'qnnpack'\n",
    "        #self.quant = quantization.QuantStub()\n",
    "        #self.dequant = quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        :param images: images, a tensor of dimensions (batch_size, 3, image_size, image_size)\n",
    "        :return: encoded images\n",
    "        \"\"\"\n",
    "#        images = self.quant(images)\n",
    "        out = self.resnet(images)  # (batch_size, 2048, image_size/32, image_size/32)\n",
    "#        out = self.dequant(out)\n",
    "        out = self.adaptive_pool(out)  # (batch_size, 2048, encoded_image_size, encoded_image_size)\n",
    "        out = out.permute(0, 2, 3, 1)  # (batch_size, encoded_image_size, encoded_image_size, 2048)\n",
    "#         out = quantization.DeQuantStub(out)\n",
    "        return out\n",
    "\n",
    "    def fine_tune(self, fine_tune=True):\n",
    "        \"\"\"\n",
    "        Allow or prevent the computation of gradients for convolutional blocks 2 through 4 of the encoder.\n",
    "\n",
    "        :param fine_tune: Allow?\n",
    "        \"\"\"\n",
    "        for p in self.resnet.parameters():\n",
    "            p.requires_grad = False\n",
    "        # If fine-tuning, only fine-tune convolutional blocks 2 through 4\n",
    "        for c in list(self.resnet.children())[5:]:\n",
    "            for p in c.parameters():\n",
    "                p.requires_grad = fine_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'models.Encoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torchvision.models.resnet.Bottleneck' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'models.DecoderWithAttention' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'models.Attention' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Softmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTMCell' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Dogukan\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Sigmoid' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(model, map_location=device)\n",
    "decoder = checkpoint['decoder']\n",
    "#torch.save(decoder,'DecoderOrig.pth')\n",
    "decoder = decoder.to(device)\n",
    "decoder.eval()\n",
    "encoder = checkpoint['encoder']\n",
    "#torch.save(encoder,'EncoderOrig.pth')\n",
    "encoder = encoder.to(device)\n",
    "encoder.eval()\n",
    "# Load word map (word2ix)\n",
    "with open(word_map, 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "rev_word_map = {v: k for k, v in word_map.items()}  # ix2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (resnet): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(14, 14))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myencoder = Encoder()\n",
    "# myencoder.eval()\n",
    "myencoder = myencoder.to(device)\n",
    "myencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = encoder.state_dict()\n",
    "sd2 = myencoder.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sd.keys():\n",
    "    sd2[key] = sd[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myencoder.load_state_dict(sd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <start> a large jetliner flying through a blue sky <end>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(encoder, decoder, img, word_map, beam_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <start> a large jetliner flying through a blue sky <end>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(myencoder, decoder, img, word_map, beam_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_my_encoder(myencoder)\n",
    "#torch.save(myencoder,'EncoderPrunedForEval.pth')\n",
    "#torch.save(decoder,'DecoderPruned.pth')\n",
    "#prune_my_encoder(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <start> a large jetliner flying through a blue sky <end>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(myencoder, decoder, img, word_map, beam_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in resnet.0 (shape = torch.Size([64, 3, 7, 7])): 24.29%\n",
      "Sparsity in resnet.4.0.conv1 (shape = torch.Size([64, 64, 1, 1])): 40.16%\n",
      "Sparsity in resnet.4.0.conv2 (shape = torch.Size([64, 64, 3, 3])): 27.43%\n",
      "Sparsity in resnet.4.0.conv3 (shape = torch.Size([256, 64, 1, 1])): 18.80%\n",
      "Sparsity in resnet.4.0.downsample.0 (shape = torch.Size([256, 64, 1, 1])): 33.92%\n",
      "Sparsity in resnet.4.1.conv1 (shape = torch.Size([64, 256, 1, 1])): 52.14%\n",
      "Sparsity in resnet.4.1.conv2 (shape = torch.Size([64, 64, 3, 3])): 65.67%\n",
      "Sparsity in resnet.4.1.conv3 (shape = torch.Size([256, 64, 1, 1])): 52.01%\n",
      "Sparsity in resnet.4.2.conv1 (shape = torch.Size([64, 256, 1, 1])): 17.96%\n",
      "Sparsity in resnet.4.2.conv2 (shape = torch.Size([64, 64, 3, 3])): 16.64%\n",
      "Sparsity in resnet.4.2.conv3 (shape = torch.Size([256, 64, 1, 1])): 25.15%\n",
      "Sparsity in resnet.5.0.conv1 (shape = torch.Size([128, 256, 1, 1])): 6.99%\n",
      "Sparsity in resnet.5.0.conv2 (shape = torch.Size([128, 128, 3, 3])): 6.88%\n",
      "Sparsity in resnet.5.0.conv3 (shape = torch.Size([512, 128, 1, 1])): 14.67%\n",
      "Sparsity in resnet.5.0.downsample.0 (shape = torch.Size([512, 256, 1, 1])): 14.98%\n",
      "Sparsity in resnet.5.1.conv1 (shape = torch.Size([128, 512, 1, 1])): 19.26%\n",
      "Sparsity in resnet.5.1.conv2 (shape = torch.Size([128, 128, 3, 3])): 7.70%\n",
      "Sparsity in resnet.5.1.conv3 (shape = torch.Size([512, 128, 1, 1])): 8.89%\n",
      "Sparsity in resnet.5.2.conv1 (shape = torch.Size([128, 512, 1, 1])): 11.29%\n",
      "Sparsity in resnet.5.2.conv2 (shape = torch.Size([128, 128, 3, 3])): 10.69%\n",
      "Sparsity in resnet.5.2.conv3 (shape = torch.Size([512, 128, 1, 1])): 7.72%\n",
      "Sparsity in resnet.5.3.conv1 (shape = torch.Size([128, 512, 1, 1])): 8.02%\n",
      "Sparsity in resnet.5.3.conv2 (shape = torch.Size([128, 128, 3, 3])): 6.89%\n",
      "Sparsity in resnet.5.3.conv3 (shape = torch.Size([512, 128, 1, 1])): 7.43%\n",
      "Sparsity in resnet.6.0.conv1 (shape = torch.Size([256, 512, 1, 1])): 7.28%\n",
      "Sparsity in resnet.6.0.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.35%\n",
      "Sparsity in resnet.6.0.conv3 (shape = torch.Size([1024, 256, 1, 1])): 12.02%\n",
      "Sparsity in resnet.6.0.downsample.0 (shape = torch.Size([1024, 512, 1, 1])): 12.17%\n",
      "Sparsity in resnet.6.1.conv1 (shape = torch.Size([256, 1024, 1, 1])): 17.47%\n",
      "Sparsity in resnet.6.1.conv2 (shape = torch.Size([256, 256, 3, 3])): 9.46%\n",
      "Sparsity in resnet.6.1.conv3 (shape = torch.Size([1024, 256, 1, 1])): 10.21%\n",
      "Sparsity in resnet.6.2.conv1 (shape = torch.Size([256, 1024, 1, 1])): 13.32%\n",
      "Sparsity in resnet.6.2.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.63%\n",
      "Sparsity in resnet.6.2.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.43%\n",
      "Sparsity in resnet.6.3.conv1 (shape = torch.Size([256, 1024, 1, 1])): 11.76%\n",
      "Sparsity in resnet.6.3.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.73%\n",
      "Sparsity in resnet.6.3.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.62%\n",
      "Sparsity in resnet.6.4.conv1 (shape = torch.Size([256, 1024, 1, 1])): 10.76%\n",
      "Sparsity in resnet.6.4.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.70%\n",
      "Sparsity in resnet.6.4.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.61%\n",
      "Sparsity in resnet.6.5.conv1 (shape = torch.Size([256, 1024, 1, 1])): 9.94%\n",
      "Sparsity in resnet.6.5.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.38%\n",
      "Sparsity in resnet.6.5.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.33%\n",
      "Sparsity in resnet.6.6.conv1 (shape = torch.Size([256, 1024, 1, 1])): 9.60%\n",
      "Sparsity in resnet.6.6.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.41%\n",
      "Sparsity in resnet.6.6.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.35%\n",
      "Sparsity in resnet.6.7.conv1 (shape = torch.Size([256, 1024, 1, 1])): 9.28%\n",
      "Sparsity in resnet.6.7.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.33%\n",
      "Sparsity in resnet.6.7.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.34%\n",
      "Sparsity in resnet.6.8.conv1 (shape = torch.Size([256, 1024, 1, 1])): 8.93%\n",
      "Sparsity in resnet.6.8.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.35%\n",
      "Sparsity in resnet.6.8.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.20%\n",
      "Sparsity in resnet.6.9.conv1 (shape = torch.Size([256, 1024, 1, 1])): 8.67%\n",
      "Sparsity in resnet.6.9.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.39%\n",
      "Sparsity in resnet.6.9.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.23%\n",
      "Sparsity in resnet.6.10.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.72%\n",
      "Sparsity in resnet.6.10.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.35%\n",
      "Sparsity in resnet.6.10.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.19%\n",
      "Sparsity in resnet.6.11.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.57%\n",
      "Sparsity in resnet.6.11.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.35%\n",
      "Sparsity in resnet.6.11.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.24%\n",
      "Sparsity in resnet.6.12.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.37%\n",
      "Sparsity in resnet.6.12.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.39%\n",
      "Sparsity in resnet.6.12.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.28%\n",
      "Sparsity in resnet.6.13.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.32%\n",
      "Sparsity in resnet.6.13.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.39%\n",
      "Sparsity in resnet.6.13.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.24%\n",
      "Sparsity in resnet.6.14.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.34%\n",
      "Sparsity in resnet.6.14.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.38%\n",
      "Sparsity in resnet.6.14.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.20%\n",
      "Sparsity in resnet.6.15.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.42%\n",
      "Sparsity in resnet.6.15.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.38%\n",
      "Sparsity in resnet.6.15.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.36%\n",
      "Sparsity in resnet.6.16.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.35%\n",
      "Sparsity in resnet.6.16.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.41%\n",
      "Sparsity in resnet.6.16.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.30%\n",
      "Sparsity in resnet.6.17.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.34%\n",
      "Sparsity in resnet.6.17.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.39%\n",
      "Sparsity in resnet.6.17.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.31%\n",
      "Sparsity in resnet.6.18.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.34%\n",
      "Sparsity in resnet.6.18.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.38%\n",
      "Sparsity in resnet.6.18.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.24%\n",
      "Sparsity in resnet.6.19.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.21%\n",
      "Sparsity in resnet.6.19.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.36%\n",
      "Sparsity in resnet.6.19.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.17%\n",
      "Sparsity in resnet.6.20.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.15%\n",
      "Sparsity in resnet.6.20.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.31%\n",
      "Sparsity in resnet.6.20.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.15%\n",
      "Sparsity in resnet.6.21.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.25%\n",
      "Sparsity in resnet.6.21.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.33%\n",
      "Sparsity in resnet.6.21.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.21%\n",
      "Sparsity in resnet.6.22.conv1 (shape = torch.Size([256, 1024, 1, 1])): 7.14%\n",
      "Sparsity in resnet.6.22.conv2 (shape = torch.Size([256, 256, 3, 3])): 7.32%\n",
      "Sparsity in resnet.6.22.conv3 (shape = torch.Size([1024, 256, 1, 1])): 7.14%\n",
      "Sparsity in resnet.7.0.conv1 (shape = torch.Size([512, 1024, 1, 1])): 7.00%\n",
      "Sparsity in resnet.7.0.conv2 (shape = torch.Size([512, 512, 3, 3])): 7.29%\n",
      "Sparsity in resnet.7.0.conv3 (shape = torch.Size([2048, 512, 1, 1])): 7.22%\n",
      "Sparsity in resnet.7.0.downsample.0 (shape = torch.Size([2048, 1024, 1, 1])): 7.29%\n",
      "Sparsity in resnet.7.1.conv1 (shape = torch.Size([512, 2048, 1, 1])): 7.30%\n",
      "Sparsity in resnet.7.1.conv2 (shape = torch.Size([512, 512, 3, 3])): 7.29%\n",
      "Sparsity in resnet.7.1.conv3 (shape = torch.Size([2048, 512, 1, 1])): 7.18%\n",
      "Sparsity in resnet.7.2.conv1 (shape = torch.Size([512, 2048, 1, 1])): 7.29%\n",
      "Sparsity in resnet.7.2.conv2 (shape = torch.Size([512, 512, 3, 3])): 7.33%\n",
      "Sparsity in resnet.7.2.conv3 (shape = torch.Size([2048, 512, 1, 1])): 7.31%\n",
      "Total sparsity in the pruned encoder: 7.89%\n"
     ]
    }
   ],
   "source": [
    "total_encoder_sparsity = 0\n",
    "den = 0\n",
    "num = 0\n",
    "for name, module in myencoder.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        print(\"Sparsity in {} (shape = {}): {:.2f}%\".format\n",
    "        (name, module.weight.shape,\n",
    "        100. * float(torch.sum(module.weight == 0))/ float(module.weight.nelement())\n",
    "        ))\n",
    "        num += float(torch.sum(module.weight == 0))\n",
    "        den += float(module.weight.nelement())\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        print(\"Sparsity in {} (shape = {}): {:.2f}%\".format\n",
    "        (name, module.weight.shape,\n",
    "        100. * float(torch.sum(module.weight == 0))/ float(module.weight.nelement())\n",
    "        ))\n",
    "        num += float(torch.sum(module.weight == 0))\n",
    "        den += float(module.weight.nelement())\n",
    "total_encoder_sparsity = 100.*num/den        \n",
    "print(\"Total sparsity in the pruned encoder: {:.2f}%\".format(total_encoder_sparsity))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderWithAttention(\n",
      "  (attention): Attention(\n",
      "    (encoder_att): DynamicQuantizedLinear(in_features=2048, out_features=512, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (decoder_att): DynamicQuantizedLinear(in_features=512, out_features=512, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (full_att): DynamicQuantizedLinear(in_features=512, out_features=1, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (relu): ReLU()\n",
      "    (softmax): Softmax(dim=1)\n",
      "  )\n",
      "  (embedding): Embedding(9490, 512)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (decode_step): LSTMCell(2560, 512, bias=1)\n",
      "  (init_h): DynamicQuantizedLinear(in_features=2048, out_features=512, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (init_c): DynamicQuantizedLinear(in_features=2048, out_features=512, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (f_beta): DynamicQuantizedLinear(in_features=512, out_features=2048, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=9490, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Quantizing the Decoder\n",
    "decoder.to(\"cpu\")\n",
    "quantized_decoder = quantization.quantize_dynamic(decoder, {torch.nn.LSTM, torch.nn.Linear}, dtype=torch.qint8)\n",
    "print(quantized_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUANTIZATION FUNCTION\n",
    "def quantize_my_model(model):\n",
    "    # set the qconfig for PTQ\n",
    "    model.qconfig = quantization.get_default_qconfig('fbgemm')\n",
    "    # set the qengine to control weight packing\n",
    "    torch.backends.quantized.engine = 'fbgemm'\n",
    "    # put model in eval mode\n",
    "    model.eval()\n",
    "    quantization.prepare(model, inplace=True)\n",
    "    quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_my_model(myencoder)\n",
    "#quantize_my_model(decoder)\n",
    "print(myencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <start> a large jetliner flying through a blue sky <end>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(myencoder, quantized_decoder, img, word_map, beam_size)\n",
    "# model.to('QuantizedCPU')\n",
    "# summary(myencoder, (3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify quantization configuration\n",
    "# # Start with simple min/max range estimation and per-tensor\n",
    "# # quantization of weights\n",
    "# myencoder.qconfig = quantization.default_qconfig\n",
    "# # Convert to quantized model\n",
    "# quantization.convert(myencoder, inplace=True)\n",
    "# # Calibrate with the training set\n",
    "# # evaluate(myModel, criterion, data_loader, neval_batches=num_calibration_batches)\n",
    "# for name, module in myencoder.named_modules(): \n",
    "#     for n, p in module.named_parameters():\n",
    "#             print(n, 'has type:', p.dtype)\n",
    "# # prunedencoder = Encoder()\n",
    "# # myencoder_state_dict = myencoder.state_dict()\n",
    "# # prunedencoder_state_dict = prunedencoder.state_dict()\n",
    "# # for key in myencoder_state_dict.keys():\n",
    "# #     print(key)\n",
    "#     #     if key in prunedencoder_state_dict.keys():\n",
    "# #         prunedencoder_state_dict[key] = myencoder_state_dict[key]\n",
    "# # prunedencoder.load_state_dict(myencoder_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summary(myencoder, (3,256,256))\n",
    "for name, param in myencoder.named_parameters():\n",
    "    print(param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpoint2 = {'encoder': myencoder}\n",
    "#torch.save(quantized_decoder,'QuantizedDecoderForEval.pth') - didnt work\n",
    "torch.save(quantized_decoder.state_dict(), \"QuantizedDecoderStateDict.pth\")\n",
    "decoder.load_state_dict(torch.load(\"QuantizedDecoderStateDict.pth\"))\n",
    "#torch.save(myencoder.state_dict(), \"QuantEncwStateDict2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = torch.load('QuantizedModel.pth', map_location=device)\n",
    "#theencoder = checkpoint['encoder']\n",
    "#torch.save(theencoder,'EncoderQuantized.pth')\n",
    "#theencoder = Encoder()\n",
    "#theencoder = theencoder.to(device)\n",
    "#theencoder.eval()\n",
    "#theencoder.load_state_dict(torch.load(\"QuantEncwStateDict2.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(theencoder, decoder, img, word_map, beam_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (resnet): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(14, 14))\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodertry = torch.load(\"EncoderPrunedForEval.pth\")\n",
    "#decodertry = torch.load(\"QuantizedDecoderForEval.pth\")\n",
    "encodertry.to(device)\n",
    "#decodertry.to(device)\n",
    "encodertry.eval()\n",
    "#decodertry.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <start> a large jetliner flying through a blue sky <end>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(encodertry, decoder, img, word_map, beam_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <start> a large jetliner flying through a blue sky <end>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(encodertry, quantized_decoder, img, word_map, beam_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 2048, 8, 8]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 128, 128]        (9,408)\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 128, 128]        (128)\n",
      "|    └─ReLU: 2-3                         [-1, 64, 128, 128]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 64, 64, 64]          --\n",
      "|    └─Sequential: 2-5                   [-1, 256, 64, 64]         --\n",
      "|    |    └─Bottleneck: 3-1              [-1, 256, 64, 64]         (75,008)\n",
      "|    |    └─Bottleneck: 3-2              [-1, 256, 64, 64]         (70,400)\n",
      "|    |    └─Bottleneck: 3-3              [-1, 256, 64, 64]         (70,400)\n",
      "|    └─Sequential: 2-6                   [-1, 512, 32, 32]         --\n",
      "|    |    └─Bottleneck: 3-4              [-1, 512, 32, 32]         379,392\n",
      "|    |    └─Bottleneck: 3-5              [-1, 512, 32, 32]         280,064\n",
      "|    |    └─Bottleneck: 3-6              [-1, 512, 32, 32]         280,064\n",
      "|    |    └─Bottleneck: 3-7              [-1, 512, 32, 32]         280,064\n",
      "|    └─Sequential: 2-7                   [-1, 1024, 16, 16]        --\n",
      "|    |    └─Bottleneck: 3-8              [-1, 1024, 16, 16]        1,512,448\n",
      "|    |    └─Bottleneck: 3-9              [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-10             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-11             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-12             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-13             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-14             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-15             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-16             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-17             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-18             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-19             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-20             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-21             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-22             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-23             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-24             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-25             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-26             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-27             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-28             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-29             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-30             [-1, 1024, 16, 16]        1,117,184\n",
      "|    └─Sequential: 2-8                   [-1, 2048, 8, 8]          --\n",
      "|    |    └─Bottleneck: 3-31             [-1, 2048, 8, 8]          6,039,552\n",
      "|    |    └─Bottleneck: 3-32             [-1, 2048, 8, 8]          4,462,592\n",
      "|    |    └─Bottleneck: 3-33             [-1, 2048, 8, 8]          4,462,592\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 2048, 14, 14]        --\n",
      "==========================================================================================\n",
      "Total params: 42,500,160\n",
      "Trainable params: 42,274,816\n",
      "Non-trainable params: 225,344\n",
      "Total mult-adds (G): 9.85\n",
      "==========================================================================================\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 293.50\n",
      "Params size (MB): 162.13\n",
      "Estimated Total Size (MB): 456.38\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 2048, 8, 8]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 128, 128]        (9,408)\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 128, 128]        (128)\n",
       "|    └─ReLU: 2-3                         [-1, 64, 128, 128]        --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 64, 64, 64]          --\n",
       "|    └─Sequential: 2-5                   [-1, 256, 64, 64]         --\n",
       "|    |    └─Bottleneck: 3-1              [-1, 256, 64, 64]         (75,008)\n",
       "|    |    └─Bottleneck: 3-2              [-1, 256, 64, 64]         (70,400)\n",
       "|    |    └─Bottleneck: 3-3              [-1, 256, 64, 64]         (70,400)\n",
       "|    └─Sequential: 2-6                   [-1, 512, 32, 32]         --\n",
       "|    |    └─Bottleneck: 3-4              [-1, 512, 32, 32]         379,392\n",
       "|    |    └─Bottleneck: 3-5              [-1, 512, 32, 32]         280,064\n",
       "|    |    └─Bottleneck: 3-6              [-1, 512, 32, 32]         280,064\n",
       "|    |    └─Bottleneck: 3-7              [-1, 512, 32, 32]         280,064\n",
       "|    └─Sequential: 2-7                   [-1, 1024, 16, 16]        --\n",
       "|    |    └─Bottleneck: 3-8              [-1, 1024, 16, 16]        1,512,448\n",
       "|    |    └─Bottleneck: 3-9              [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-10             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-11             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-12             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-13             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-14             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-15             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-16             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-17             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-18             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-19             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-20             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-21             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-22             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-23             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-24             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-25             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-26             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-27             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-28             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-29             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-30             [-1, 1024, 16, 16]        1,117,184\n",
       "|    └─Sequential: 2-8                   [-1, 2048, 8, 8]          --\n",
       "|    |    └─Bottleneck: 3-31             [-1, 2048, 8, 8]          6,039,552\n",
       "|    |    └─Bottleneck: 3-32             [-1, 2048, 8, 8]          4,462,592\n",
       "|    |    └─Bottleneck: 3-33             [-1, 2048, 8, 8]          4,462,592\n",
       "├─AdaptiveAvgPool2d: 1-2                 [-1, 2048, 14, 14]        --\n",
       "==========================================================================================\n",
       "Total params: 42,500,160\n",
       "Trainable params: 42,274,816\n",
       "Non-trainable params: 225,344\n",
       "Total mult-adds (G): 9.85\n",
       "==========================================================================================\n",
       "Input size (MB): 0.75\n",
       "Forward/backward pass size (MB): 293.50\n",
       "Params size (MB): 162.13\n",
       "Estimated Total Size (MB): 456.38\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(encodertry,(3,256,256),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(quantized_decoder,input_size = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderWithAttention(\n",
      "  (attention): Attention(\n",
      "    (encoder_att): DynamicQuantizedLinear(in_features=2048, out_features=512, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (decoder_att): DynamicQuantizedLinear(in_features=512, out_features=512, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (full_att): DynamicQuantizedLinear(in_features=512, out_features=1, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (relu): ReLU()\n",
      "    (softmax): Softmax(dim=1)\n",
      "  )\n",
      "  (embedding): Embedding(9490, 512)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (decode_step): LSTMCell(2560, 512, bias=1)\n",
      "  (init_h): DynamicQuantizedLinear(in_features=2048, out_features=512, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (init_c): DynamicQuantizedLinear(in_features=2048, out_features=512, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (f_beta): DynamicQuantizedLinear(in_features=512, out_features=2048, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=9490, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(quantized_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(quantized_decoder.to(device),(3,400,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myencoder.to(device)\n",
    "inference(myencoder, decoder, img, word_map, beam_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 2048, 8, 8]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 128, 128]        (9,408)\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 128, 128]        (128)\n",
      "|    └─ReLU: 2-3                         [-1, 64, 128, 128]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 64, 64, 64]          --\n",
      "|    └─Sequential: 2-5                   [-1, 256, 64, 64]         --\n",
      "|    |    └─Bottleneck: 3-1              [-1, 256, 64, 64]         (75,008)\n",
      "|    |    └─Bottleneck: 3-2              [-1, 256, 64, 64]         (70,400)\n",
      "|    |    └─Bottleneck: 3-3              [-1, 256, 64, 64]         (70,400)\n",
      "|    └─Sequential: 2-6                   [-1, 512, 32, 32]         --\n",
      "|    |    └─Bottleneck: 3-4              [-1, 512, 32, 32]         379,392\n",
      "|    |    └─Bottleneck: 3-5              [-1, 512, 32, 32]         280,064\n",
      "|    |    └─Bottleneck: 3-6              [-1, 512, 32, 32]         280,064\n",
      "|    |    └─Bottleneck: 3-7              [-1, 512, 32, 32]         280,064\n",
      "|    └─Sequential: 2-7                   [-1, 1024, 16, 16]        --\n",
      "|    |    └─Bottleneck: 3-8              [-1, 1024, 16, 16]        1,512,448\n",
      "|    |    └─Bottleneck: 3-9              [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-10             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-11             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-12             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-13             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-14             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-15             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-16             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-17             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-18             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-19             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-20             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-21             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-22             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-23             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-24             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-25             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-26             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-27             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-28             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-29             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-30             [-1, 1024, 16, 16]        1,117,184\n",
      "|    └─Sequential: 2-8                   [-1, 2048, 8, 8]          --\n",
      "|    |    └─Bottleneck: 3-31             [-1, 2048, 8, 8]          6,039,552\n",
      "|    |    └─Bottleneck: 3-32             [-1, 2048, 8, 8]          4,462,592\n",
      "|    |    └─Bottleneck: 3-33             [-1, 2048, 8, 8]          4,462,592\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 2048, 14, 14]        --\n",
      "==========================================================================================\n",
      "Total params: 42,500,160\n",
      "Trainable params: 42,274,816\n",
      "Non-trainable params: 225,344\n",
      "Total mult-adds (G): 9.85\n",
      "==========================================================================================\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 293.50\n",
      "Params size (MB): 162.13\n",
      "Estimated Total Size (MB): 456.38\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 2048, 8, 8]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 128, 128]        (9,408)\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 128, 128]        (128)\n",
       "|    └─ReLU: 2-3                         [-1, 64, 128, 128]        --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 64, 64, 64]          --\n",
       "|    └─Sequential: 2-5                   [-1, 256, 64, 64]         --\n",
       "|    |    └─Bottleneck: 3-1              [-1, 256, 64, 64]         (75,008)\n",
       "|    |    └─Bottleneck: 3-2              [-1, 256, 64, 64]         (70,400)\n",
       "|    |    └─Bottleneck: 3-3              [-1, 256, 64, 64]         (70,400)\n",
       "|    └─Sequential: 2-6                   [-1, 512, 32, 32]         --\n",
       "|    |    └─Bottleneck: 3-4              [-1, 512, 32, 32]         379,392\n",
       "|    |    └─Bottleneck: 3-5              [-1, 512, 32, 32]         280,064\n",
       "|    |    └─Bottleneck: 3-6              [-1, 512, 32, 32]         280,064\n",
       "|    |    └─Bottleneck: 3-7              [-1, 512, 32, 32]         280,064\n",
       "|    └─Sequential: 2-7                   [-1, 1024, 16, 16]        --\n",
       "|    |    └─Bottleneck: 3-8              [-1, 1024, 16, 16]        1,512,448\n",
       "|    |    └─Bottleneck: 3-9              [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-10             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-11             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-12             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-13             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-14             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-15             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-16             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-17             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-18             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-19             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-20             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-21             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-22             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-23             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-24             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-25             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-26             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-27             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-28             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-29             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-30             [-1, 1024, 16, 16]        1,117,184\n",
       "|    └─Sequential: 2-8                   [-1, 2048, 8, 8]          --\n",
       "|    |    └─Bottleneck: 3-31             [-1, 2048, 8, 8]          6,039,552\n",
       "|    |    └─Bottleneck: 3-32             [-1, 2048, 8, 8]          4,462,592\n",
       "|    |    └─Bottleneck: 3-33             [-1, 2048, 8, 8]          4,462,592\n",
       "├─AdaptiveAvgPool2d: 1-2                 [-1, 2048, 14, 14]        --\n",
       "==========================================================================================\n",
       "Total params: 42,500,160\n",
       "Trainable params: 42,274,816\n",
       "Non-trainable params: 225,344\n",
       "Total mult-adds (G): 9.85\n",
       "==========================================================================================\n",
       "Input size (MB): 0.75\n",
       "Forward/backward pass size (MB): 293.50\n",
       "Params size (MB): 162.13\n",
       "Estimated Total Size (MB): 456.38\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(myencoder,(3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(encoder,(3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_lengths = torch.tensor([[11],\n",
    "        [12],\n",
    "        [10],\n",
    "        [14],\n",
    "        [14],\n",
    "        [10],\n",
    "        [12],\n",
    "        [12],\n",
    "        [10],\n",
    "        [11],\n",
    "        [11],\n",
    "        [12],\n",
    "        [12],\n",
    "        [11],\n",
    "        [13],\n",
    "        [10]], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_captions = torch.tensor([[9488,    1,  375,  976,  157,   61,   23,  156, 1717, 1458, 9489,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488, 1819,    1, 1725,   28,  349,  823,  217,   32,    1,  764, 9489,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,    1,    2,   11,    1,  287,    6,    1, 1490, 9489,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,    1,    4,  430,   28,   46, 1752,   28,  156,  419, 3329,   28,\n",
    "          580, 9489,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,    1,    2,   71,    6,   14,   16,  743,   17,    1,  184,   91,\n",
    "          336, 9489,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,    1,   45,  336,    3,    1,  696,  690,  577, 9489,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488, 2078, 2257,    6,    1,  102,   28,   90,   35, 2342,   86, 9489,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,    1,   92,   17,   93,  609,    6,  205,   17,   14, 2826, 9489,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,  747,  887,  119,  564,    3, 2653,   28, 4110, 9489,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,  167, 1220,   32,  288,    3,  349,  603,   28,  419, 9489,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,    1, 1881,   98,   79,   14, 1533,   17,    1, 2039, 9489,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,   14,   21,   35,   43,  245,    1, 2343,    3,    1,   53, 9489,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,   49,  179,  164, 1287,   17,    1,    2, 2077,    1, 2015, 9489,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,    1,  230,  996,  134,  164, 1640,  371,    1,  940, 9489,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,    1, 1428, 1051,   28,   41,  369,  179,   66, 4450,   23, 4450,\n",
    "         9489,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0],\n",
    "        [9488,    1,    2,   71,    6,    1,  720,   11, 1348, 9489,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "            0,    0,    0,    0]], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(caption_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = torch.tensor([[[1.5874, 0.0000, 3.9018,  ..., 1.1873, 0.0000, 0.0000],\n",
    "         [0.7937, 0.0000, 1.9509,  ..., 0.5936, 0.0000, 0.0000],\n",
    "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
    "         ...,\n",
    "         [1.4390, 0.0000, 1.3281,  ..., 0.2475, 0.0000, 0.0000],\n",
    "         [1.8537, 0.9871, 1.0184,  ..., 0.2423, 0.1009, 0.0000],\n",
    "         [2.2683, 1.9742, 0.7086,  ..., 0.2370, 0.2018, 0.0000]],\n",
    "\n",
    "        [[1.5874, 0.0000, 3.9018,  ..., 1.1873, 0.0000, 0.0000],\n",
    "         [0.7937, 0.0000, 1.9509,  ..., 0.5936, 0.0000, 0.0000],\n",
    "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
    "         ...,\n",
    "         [1.4390, 0.0000, 1.3281,  ..., 0.2475, 0.0000, 0.0000],\n",
    "         [1.8537, 0.9871, 1.0184,  ..., 0.2423, 0.1009, 0.0000],\n",
    "         [2.2683, 1.9742, 0.7086,  ..., 0.2370, 0.2018, 0.0000]],\n",
    "\n",
    "        [[1.5874, 0.0000, 3.9018,  ..., 1.1873, 0.0000, 0.0000],\n",
    "         [0.7937, 0.0000, 1.9509,  ..., 0.5936, 0.0000, 0.0000],\n",
    "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
    "         ...,\n",
    "         [1.4390, 0.0000, 1.3281,  ..., 0.2475, 0.0000, 0.0000],\n",
    "         [1.8537, 0.9871, 1.0184,  ..., 0.2423, 0.1009, 0.0000],\n",
    "         [2.2683, 1.9742, 0.7086,  ..., 0.2370, 0.2018, 0.0000]],\n",
    "\n",
    "        ...,\n",
    "\n",
    "        [[1.5764, 0.0000, 3.8673,  ..., 1.1372, 0.0000, 0.0000],\n",
    "         [0.7882, 0.0000, 1.9337,  ..., 0.5686, 0.0000, 0.0000],\n",
    "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
    "         ...,\n",
    "         [0.2420, 0.0000, 0.0000,  ..., 0.0000, 0.4471, 0.0000],\n",
    "         [0.4089, 0.0457, 0.0000,  ..., 0.0000, 0.5250, 0.0000],\n",
    "         [0.5757, 0.0915, 0.0000,  ..., 0.0000, 0.6030, 0.0000]],\n",
    "\n",
    "        [[1.5874, 0.0000, 3.9018,  ..., 1.1873, 0.0000, 0.0000],\n",
    "         [0.7937, 0.0000, 1.9509,  ..., 0.5936, 0.0000, 0.0000],\n",
    "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
    "         ...,\n",
    "         [1.4390, 0.0000, 1.3281,  ..., 0.2475, 0.0000, 0.0000],\n",
    "         [1.8537, 0.9871, 1.0184,  ..., 0.2423, 0.1009, 0.0000],\n",
    "         [2.2683, 1.9742, 0.7086,  ..., 0.2370, 0.2018, 0.0000]],\n",
    "\n",
    "        [[1.5874, 0.0000, 3.9018,  ..., 1.1873, 0.0000, 0.0000],\n",
    "         [0.7937, 0.0000, 1.9509,  ..., 0.5936, 0.0000, 0.0000],\n",
    "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
    "         ...,\n",
    "         [1.4390, 0.0000, 1.3281,  ..., 0.2475, 0.0000, 0.0000],\n",
    "         [1.8537, 0.9871, 1.0184,  ..., 0.2423, 0.1009, 0.0000],\n",
    "         [2.2683, 1.9742, 0.7086,  ..., 0.2370, 0.2018, 0.0000]]],\n",
    "       device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = 2*torch.rand(16,196,2048,device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Embedding: 1-1                         [-1, 52, 512]             4,858,880\n",
      "├─Linear: 1-2                            [-1, 512]                 1,049,088\n",
      "├─Linear: 1-3                            [-1, 512]                 1,049,088\n",
      "├─Attention: 1-4                         [-1, 2048]                --\n",
      "|    └─Linear: 2-1                       [-1, 196, 512]            1,049,088\n",
      "|    └─Linear: 2-2                       [-1, 512]                 262,656\n",
      "|    └─ReLU: 2-3                         [-1, 196, 512]            --\n",
      "|    └─Linear: 2-4                       [-1, 196, 1]              513\n",
      "|    └─Softmax: 2-5                      [-1, 196]                 --\n",
      "├─Linear: 1-5                            [-1, 2048]                1,050,624\n",
      "├─Sigmoid: 1-6                           [-1, 2048]                --\n",
      "├─LSTMCell: 1-7                          [-1, 512]                 6,295,552\n",
      "├─Dropout: 1-8                           [-1, 512]                 --\n",
      "├─Linear: 1-9                            [-1, 9490]                4,868,370\n",
      "├─Attention: 1-10                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-6                       [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-7                       [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-8                         [-1, 196, 512]            --\n",
      "|    └─Linear: 2-9                       [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-10                     [-1, 196]                 --\n",
      "├─Linear: 1-11                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-12                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-13                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-14                          [-1, 512]                 --\n",
      "├─Linear: 1-15                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-16                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-11                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-12                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-13                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-14                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-15                     [-1, 196]                 --\n",
      "├─Linear: 1-17                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-18                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-19                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-20                          [-1, 512]                 --\n",
      "├─Linear: 1-21                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-22                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-16                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-17                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-18                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-19                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-20                     [-1, 196]                 --\n",
      "├─Linear: 1-23                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-24                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-25                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-26                          [-1, 512]                 --\n",
      "├─Linear: 1-27                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-28                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-21                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-22                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-23                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-24                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-25                     [-1, 196]                 --\n",
      "├─Linear: 1-29                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-30                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-31                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-32                          [-1, 512]                 --\n",
      "├─Linear: 1-33                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-34                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-26                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-27                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-28                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-29                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-30                     [-1, 196]                 --\n",
      "├─Linear: 1-35                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-36                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-37                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-38                          [-1, 512]                 --\n",
      "├─Linear: 1-39                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-40                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-31                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-32                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-33                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-34                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-35                     [-1, 196]                 --\n",
      "├─Linear: 1-41                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-42                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-43                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-44                          [-1, 512]                 --\n",
      "├─Linear: 1-45                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-46                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-36                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-37                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-38                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-39                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-40                     [-1, 196]                 --\n",
      "├─Linear: 1-47                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-48                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-49                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-50                          [-1, 512]                 --\n",
      "├─Linear: 1-51                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-52                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-41                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-42                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-43                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-44                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-45                     [-1, 196]                 --\n",
      "├─Linear: 1-53                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-54                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-55                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-56                          [-1, 512]                 --\n",
      "├─Linear: 1-57                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-58                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-46                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-47                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-48                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-49                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-50                     [-1, 196]                 --\n",
      "├─Linear: 1-59                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-60                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-61                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-62                          [-1, 512]                 --\n",
      "├─Linear: 1-63                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-64                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-51                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-52                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-53                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-54                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-55                     [-1, 196]                 --\n",
      "├─Linear: 1-65                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-66                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-67                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-68                          [-1, 512]                 --\n",
      "├─Linear: 1-69                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-70                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-56                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-57                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-58                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-59                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-60                     [-1, 196]                 --\n",
      "├─Linear: 1-71                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-72                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-73                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-74                          [-1, 512]                 --\n",
      "├─Linear: 1-75                           [-1, 9490]                (recursive)\n",
      "├─Attention: 1-76                        [-1, 2048]                (recursive)\n",
      "|    └─Linear: 2-61                      [-1, 196, 512]            (recursive)\n",
      "|    └─Linear: 2-62                      [-1, 512]                 (recursive)\n",
      "|    └─ReLU: 2-63                        [-1, 196, 512]            --\n",
      "|    └─Linear: 2-64                      [-1, 196, 1]              (recursive)\n",
      "|    └─Softmax: 2-65                     [-1, 196]                 --\n",
      "├─Linear: 1-77                           [-1, 2048]                (recursive)\n",
      "├─Sigmoid: 1-78                          [-1, 2048]                --\n",
      "├─LSTMCell: 1-79                         [-1, 512]                 (recursive)\n",
      "├─Dropout: 1-80                          [-1, 512]                 --\n",
      "├─Linear: 1-81                           [-1, 9490]                (recursive)\n",
      "==========================================================================================\n",
      "Total params: 20,483,859\n",
      "Trainable params: 20,483,859\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 199.63\n",
      "==========================================================================================\n",
      "Input size (MB): 24.50\n",
      "Forward/backward pass size (MB): 1.07\n",
      "Params size (MB): 78.14\n",
      "Estimated Total Size (MB): 103.71\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Embedding: 1-1                         [-1, 52, 512]             4,858,880\n",
       "├─Linear: 1-2                            [-1, 512]                 1,049,088\n",
       "├─Linear: 1-3                            [-1, 512]                 1,049,088\n",
       "├─Attention: 1-4                         [-1, 2048]                --\n",
       "|    └─Linear: 2-1                       [-1, 196, 512]            1,049,088\n",
       "|    └─Linear: 2-2                       [-1, 512]                 262,656\n",
       "|    └─ReLU: 2-3                         [-1, 196, 512]            --\n",
       "|    └─Linear: 2-4                       [-1, 196, 1]              513\n",
       "|    └─Softmax: 2-5                      [-1, 196]                 --\n",
       "├─Linear: 1-5                            [-1, 2048]                1,050,624\n",
       "├─Sigmoid: 1-6                           [-1, 2048]                --\n",
       "├─LSTMCell: 1-7                          [-1, 512]                 6,295,552\n",
       "├─Dropout: 1-8                           [-1, 512]                 --\n",
       "├─Linear: 1-9                            [-1, 9490]                4,868,370\n",
       "├─Attention: 1-10                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-6                       [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-7                       [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-8                         [-1, 196, 512]            --\n",
       "|    └─Linear: 2-9                       [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-10                     [-1, 196]                 --\n",
       "├─Linear: 1-11                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-12                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-13                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-14                          [-1, 512]                 --\n",
       "├─Linear: 1-15                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-16                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-11                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-12                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-13                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-14                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-15                     [-1, 196]                 --\n",
       "├─Linear: 1-17                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-18                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-19                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-20                          [-1, 512]                 --\n",
       "├─Linear: 1-21                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-22                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-16                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-17                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-18                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-19                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-20                     [-1, 196]                 --\n",
       "├─Linear: 1-23                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-24                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-25                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-26                          [-1, 512]                 --\n",
       "├─Linear: 1-27                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-28                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-21                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-22                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-23                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-24                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-25                     [-1, 196]                 --\n",
       "├─Linear: 1-29                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-30                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-31                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-32                          [-1, 512]                 --\n",
       "├─Linear: 1-33                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-34                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-26                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-27                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-28                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-29                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-30                     [-1, 196]                 --\n",
       "├─Linear: 1-35                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-36                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-37                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-38                          [-1, 512]                 --\n",
       "├─Linear: 1-39                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-40                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-31                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-32                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-33                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-34                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-35                     [-1, 196]                 --\n",
       "├─Linear: 1-41                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-42                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-43                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-44                          [-1, 512]                 --\n",
       "├─Linear: 1-45                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-46                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-36                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-37                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-38                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-39                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-40                     [-1, 196]                 --\n",
       "├─Linear: 1-47                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-48                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-49                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-50                          [-1, 512]                 --\n",
       "├─Linear: 1-51                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-52                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-41                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-42                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-43                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-44                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-45                     [-1, 196]                 --\n",
       "├─Linear: 1-53                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-54                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-55                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-56                          [-1, 512]                 --\n",
       "├─Linear: 1-57                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-58                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-46                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-47                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-48                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-49                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-50                     [-1, 196]                 --\n",
       "├─Linear: 1-59                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-60                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-61                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-62                          [-1, 512]                 --\n",
       "├─Linear: 1-63                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-64                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-51                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-52                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-53                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-54                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-55                     [-1, 196]                 --\n",
       "├─Linear: 1-65                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-66                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-67                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-68                          [-1, 512]                 --\n",
       "├─Linear: 1-69                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-70                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-56                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-57                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-58                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-59                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-60                     [-1, 196]                 --\n",
       "├─Linear: 1-71                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-72                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-73                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-74                          [-1, 512]                 --\n",
       "├─Linear: 1-75                           [-1, 9490]                (recursive)\n",
       "├─Attention: 1-76                        [-1, 2048]                (recursive)\n",
       "|    └─Linear: 2-61                      [-1, 196, 512]            (recursive)\n",
       "|    └─Linear: 2-62                      [-1, 512]                 (recursive)\n",
       "|    └─ReLU: 2-63                        [-1, 196, 512]            --\n",
       "|    └─Linear: 2-64                      [-1, 196, 1]              (recursive)\n",
       "|    └─Softmax: 2-65                     [-1, 196]                 --\n",
       "├─Linear: 1-77                           [-1, 2048]                (recursive)\n",
       "├─Sigmoid: 1-78                          [-1, 2048]                --\n",
       "├─LSTMCell: 1-79                         [-1, 512]                 (recursive)\n",
       "├─Dropout: 1-80                          [-1, 512]                 --\n",
       "├─Linear: 1-81                           [-1, 9490]                (recursive)\n",
       "==========================================================================================\n",
       "Total params: 20,483,859\n",
       "Trainable params: 20,483,859\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 199.63\n",
       "==========================================================================================\n",
       "Input size (MB): 24.50\n",
       "Forward/backward pass size (MB): 1.07\n",
       "Params size (MB): 78.14\n",
       "Estimated Total Size (MB): 103.71\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=decoder,input_data=encoder_out,encoded_captions=encoded_captions,caption_lengths=caption_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchsummary. See above stack traces for more details. Executed layers up to: [Embedding: 1-1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dogukan\\TUMMSCE\\ATCE\\image-captioning-on-pytorch-master\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, encoder_out, encoded_captions, caption_lengths)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;31m# Initialize LSTM state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (batch_size, decoder_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dogukan\\TUMMSCE\\ATCE\\image-captioning-on-pytorch-master\\models.py\u001b[0m in \u001b[0;36minit_hidden_state\u001b[1;34m(self, encoder_out)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mmean_encoder_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_encoder_out\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (batch_size, decoder_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_encoder_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torch\\nn\\quantized\\dynamic\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 Y = torch.ops.quantized.linear_dynamic(\n\u001b[0m\u001b[0;32m     49\u001b[0m                     x, self._packed_params._packed_params, reduce_range=True)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Could not run 'quantized::linear_dynamic' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear_dynamic' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at ..\\aten\\src\\ATen\\native\\quantized\\cpu\\qlinear_dynamic.cpp:479 [kernel]\nBackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:35 [backend fallback]\nAutogradCPU: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:39 [backend fallback]\nAutogradCUDA: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:47 [backend fallback]\nAutogradXLA: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:51 [backend fallback]\nAutogradLazy: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:55 [backend fallback]\nAutogradXPU: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:43 [backend fallback]\nAutogradMLC: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:59 [backend fallback]\nTracer: registered at ..\\torch\\csrc\\autograd\\TraceTypeManual.cpp:291 [backend fallback]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ..\\aten\\src\\ATen\\BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13864/228063164.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#caption_lengths = torch.quantization.QuantStub(caption_lengths)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#quantized_decoder.to(\"cpu\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquantized_decoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoded_captions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoded_captions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcaption_lengths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaption_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchlatest\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mexecuted_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msummary_list\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuted\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    144\u001b[0m                 \u001b[1;34m\"Failed to run torchsummary. See above stack traces for more details. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m                 \u001b[1;34m\"Executed layers up to: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecuted_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: [Embedding: 1-1]"
     ]
    }
   ],
   "source": [
    "#encoder_out = torch.quantization.QuantStub(encoder_out,qconfig)\n",
    "#encoded_captions = torch.quantization.QuantStub(encoded_captions)\n",
    "#caption_lengths = torch.quantization.QuantStub(caption_lengths)\n",
    "#quantized_decoder.to(\"cpu\")\n",
    "summary(model=quantized_decoder,input_data=encoder_out,encoded_captions=encoded_captions,caption_lengths=caption_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "224556cf7c5c9b055ae49a6675c30d5f2054c9ee267b704439a1be7caf4d323c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import torch_pruning as tp\n",
    "import torchvision.models as models\n",
    "import caption\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoded_image_size=14):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_image_size = encoded_image_size\n",
    "\n",
    "        #resnet = torchvision.models.resnet101(pretrained=True)  # pretrained ImageNet ResNet-101\n",
    "        resnet = models.resnet101()\n",
    "        #resnet.load_state_dict(torch.load(\"resnet101-2.pth\"))\n",
    "\n",
    "        # Remove linear and pool layers (since we're not doing classification)\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = torch.nn.Sequential(*modules)\n",
    "\n",
    "        # Resize image to fixed size to allow input images of variable size\n",
    "        self.adaptive_pool = torch.nn.AdaptiveAvgPool2d((encoded_image_size, encoded_image_size))\n",
    "\n",
    "        self.fine_tune()\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        :param images: images, a tensor of dimensions (batch_size, 3, image_size, image_size)\n",
    "        :return: encoded images\n",
    "        \"\"\"\n",
    "        out = self.resnet(images)  # (batch_size, 2048, image_size/32, image_size/32)\n",
    "        out = self.adaptive_pool(out)  # (batch_size, 2048, encoded_image_size, encoded_image_size)\n",
    "        out = out.permute(0, 2, 3, 1)  # (batch_size, encoded_image_size, encoded_image_size, 2048)\n",
    "        return out\n",
    "\n",
    "    def fine_tune(self, fine_tune=True):\n",
    "        \"\"\"\n",
    "        Allow or prevent the computation of gradients for convolutional blocks 2 through 4 of the encoder.\n",
    "\n",
    "        :param fine_tune: Allow?\n",
    "        \"\"\"\n",
    "        for p in self.resnet.parameters():\n",
    "            p.requires_grad = False\n",
    "        # If fine-tuning, only fine-tune convolutional blocks 2 through 4\n",
    "        for c in list(self.resnet.children())[5:]:\n",
    "            for p in c.parameters():\n",
    "                p.requires_grad = fine_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'models.Encoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torchvision.models.resnet.Bottleneck' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'models.DecoderWithAttention' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'models.Attention' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Softmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTMCell' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Sigmoid' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 64, 64]             512\n",
      "           Conv2d-13          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 64, 64]             512\n",
      "             ReLU-15          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-16          [-1, 256, 64, 64]               0\n",
      "           Conv2d-17           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 64, 64]             128\n",
      "             ReLU-19           [-1, 64, 64, 64]               0\n",
      "           Conv2d-20           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 64, 64]             128\n",
      "             ReLU-22           [-1, 64, 64, 64]               0\n",
      "           Conv2d-23          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 64, 64]             512\n",
      "             ReLU-25          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-26          [-1, 256, 64, 64]               0\n",
      "           Conv2d-27           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 64, 64]             128\n",
      "             ReLU-29           [-1, 64, 64, 64]               0\n",
      "           Conv2d-30           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 64, 64]             128\n",
      "             ReLU-32           [-1, 64, 64, 64]               0\n",
      "           Conv2d-33          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 64, 64]             512\n",
      "             ReLU-35          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-36          [-1, 256, 64, 64]               0\n",
      "           Conv2d-37          [-1, 128, 64, 64]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 64, 64]             256\n",
      "             ReLU-39          [-1, 128, 64, 64]               0\n",
      "           Conv2d-40          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 32, 32]             256\n",
      "             ReLU-42          [-1, 128, 32, 32]               0\n",
      "           Conv2d-43          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
      "           Conv2d-45          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-47          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 32, 32]             256\n",
      "             ReLU-51          [-1, 128, 32, 32]               0\n",
      "           Conv2d-52          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 32, 32]             256\n",
      "             ReLU-54          [-1, 128, 32, 32]               0\n",
      "           Conv2d-55          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-57          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-58          [-1, 512, 32, 32]               0\n",
      "           Conv2d-59          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 32, 32]             256\n",
      "             ReLU-61          [-1, 128, 32, 32]               0\n",
      "           Conv2d-62          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 32, 32]             256\n",
      "             ReLU-64          [-1, 128, 32, 32]               0\n",
      "           Conv2d-65          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-67          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-68          [-1, 512, 32, 32]               0\n",
      "           Conv2d-69          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 32, 32]             256\n",
      "             ReLU-71          [-1, 128, 32, 32]               0\n",
      "           Conv2d-72          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 32, 32]             256\n",
      "             ReLU-74          [-1, 128, 32, 32]               0\n",
      "           Conv2d-75          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-77          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-78          [-1, 512, 32, 32]               0\n",
      "           Conv2d-79          [-1, 256, 32, 32]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 32, 32]             512\n",
      "             ReLU-81          [-1, 256, 32, 32]               0\n",
      "           Conv2d-82          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 16, 16]             512\n",
      "             ReLU-84          [-1, 256, 16, 16]               0\n",
      "           Conv2d-85         [-1, 1024, 16, 16]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n",
      "           Conv2d-87         [-1, 1024, 16, 16]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-89         [-1, 1024, 16, 16]               0\n",
      "       Bottleneck-90         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-91          [-1, 256, 16, 16]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 16, 16]             512\n",
      "             ReLU-93          [-1, 256, 16, 16]               0\n",
      "           Conv2d-94          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 16, 16]             512\n",
      "             ReLU-96          [-1, 256, 16, 16]               0\n",
      "           Conv2d-97         [-1, 1024, 16, 16]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-99         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-100         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-101          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 16, 16]             512\n",
      "            ReLU-103          [-1, 256, 16, 16]               0\n",
      "          Conv2d-104          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 16, 16]             512\n",
      "            ReLU-106          [-1, 256, 16, 16]               0\n",
      "          Conv2d-107         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-109         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-110         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-111          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 16, 16]             512\n",
      "            ReLU-113          [-1, 256, 16, 16]               0\n",
      "          Conv2d-114          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 16, 16]             512\n",
      "            ReLU-116          [-1, 256, 16, 16]               0\n",
      "          Conv2d-117         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-119         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-120         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-121          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 16, 16]             512\n",
      "            ReLU-123          [-1, 256, 16, 16]               0\n",
      "          Conv2d-124          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 16, 16]             512\n",
      "            ReLU-126          [-1, 256, 16, 16]               0\n",
      "          Conv2d-127         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-129         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-130         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-131          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 16, 16]             512\n",
      "            ReLU-133          [-1, 256, 16, 16]               0\n",
      "          Conv2d-134          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 16, 16]             512\n",
      "            ReLU-136          [-1, 256, 16, 16]               0\n",
      "          Conv2d-137         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-139         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-140         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-141          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 16, 16]             512\n",
      "            ReLU-143          [-1, 256, 16, 16]               0\n",
      "          Conv2d-144          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 16, 16]             512\n",
      "            ReLU-146          [-1, 256, 16, 16]               0\n",
      "          Conv2d-147         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-149         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-150         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-151          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 16, 16]             512\n",
      "            ReLU-153          [-1, 256, 16, 16]               0\n",
      "          Conv2d-154          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 16, 16]             512\n",
      "            ReLU-156          [-1, 256, 16, 16]               0\n",
      "          Conv2d-157         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-159         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-160         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-161          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 16, 16]             512\n",
      "            ReLU-163          [-1, 256, 16, 16]               0\n",
      "          Conv2d-164          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 16, 16]             512\n",
      "            ReLU-166          [-1, 256, 16, 16]               0\n",
      "          Conv2d-167         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-169         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-170         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-171          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 16, 16]             512\n",
      "            ReLU-173          [-1, 256, 16, 16]               0\n",
      "          Conv2d-174          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 16, 16]             512\n",
      "            ReLU-176          [-1, 256, 16, 16]               0\n",
      "          Conv2d-177         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-179         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-180         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-181          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 16, 16]             512\n",
      "            ReLU-183          [-1, 256, 16, 16]               0\n",
      "          Conv2d-184          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 16, 16]             512\n",
      "            ReLU-186          [-1, 256, 16, 16]               0\n",
      "          Conv2d-187         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-189         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-190         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-191          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 16, 16]             512\n",
      "            ReLU-193          [-1, 256, 16, 16]               0\n",
      "          Conv2d-194          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 16, 16]             512\n",
      "            ReLU-196          [-1, 256, 16, 16]               0\n",
      "          Conv2d-197         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-199         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-200         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-201          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 16, 16]             512\n",
      "            ReLU-203          [-1, 256, 16, 16]               0\n",
      "          Conv2d-204          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 16, 16]             512\n",
      "            ReLU-206          [-1, 256, 16, 16]               0\n",
      "          Conv2d-207         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-209         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-210         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-211          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 16, 16]             512\n",
      "            ReLU-213          [-1, 256, 16, 16]               0\n",
      "          Conv2d-214          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 16, 16]             512\n",
      "            ReLU-216          [-1, 256, 16, 16]               0\n",
      "          Conv2d-217         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-219         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-220         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-221          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 16, 16]             512\n",
      "            ReLU-223          [-1, 256, 16, 16]               0\n",
      "          Conv2d-224          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 16, 16]             512\n",
      "            ReLU-226          [-1, 256, 16, 16]               0\n",
      "          Conv2d-227         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-229         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-230         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-231          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 16, 16]             512\n",
      "            ReLU-233          [-1, 256, 16, 16]               0\n",
      "          Conv2d-234          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 16, 16]             512\n",
      "            ReLU-236          [-1, 256, 16, 16]               0\n",
      "          Conv2d-237         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-239         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-240         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-241          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 16, 16]             512\n",
      "            ReLU-243          [-1, 256, 16, 16]               0\n",
      "          Conv2d-244          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 16, 16]             512\n",
      "            ReLU-246          [-1, 256, 16, 16]               0\n",
      "          Conv2d-247         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-249         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-250         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-251          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 16, 16]             512\n",
      "            ReLU-253          [-1, 256, 16, 16]               0\n",
      "          Conv2d-254          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 16, 16]             512\n",
      "            ReLU-256          [-1, 256, 16, 16]               0\n",
      "          Conv2d-257         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-259         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-260         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-261          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 16, 16]             512\n",
      "            ReLU-263          [-1, 256, 16, 16]               0\n",
      "          Conv2d-264          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 16, 16]             512\n",
      "            ReLU-266          [-1, 256, 16, 16]               0\n",
      "          Conv2d-267         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-269         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-270         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-271          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 16, 16]             512\n",
      "            ReLU-273          [-1, 256, 16, 16]               0\n",
      "          Conv2d-274          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 16, 16]             512\n",
      "            ReLU-276          [-1, 256, 16, 16]               0\n",
      "          Conv2d-277         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-279         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-280         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-281          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 16, 16]             512\n",
      "            ReLU-283          [-1, 256, 16, 16]               0\n",
      "          Conv2d-284          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 16, 16]             512\n",
      "            ReLU-286          [-1, 256, 16, 16]               0\n",
      "          Conv2d-287         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-289         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-290         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-291          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 16, 16]             512\n",
      "            ReLU-293          [-1, 256, 16, 16]               0\n",
      "          Conv2d-294          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 16, 16]             512\n",
      "            ReLU-296          [-1, 256, 16, 16]               0\n",
      "          Conv2d-297         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-299         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-300         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-301          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 16, 16]             512\n",
      "            ReLU-303          [-1, 256, 16, 16]               0\n",
      "          Conv2d-304          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 16, 16]             512\n",
      "            ReLU-306          [-1, 256, 16, 16]               0\n",
      "          Conv2d-307         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-309         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-310         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-311          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-312          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-313          [-1, 512, 16, 16]               0\n",
      "          Conv2d-314            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-315            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-316            [-1, 512, 8, 8]               0\n",
      "          Conv2d-317           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-318           [-1, 2048, 8, 8]           4,096\n",
      "          Conv2d-319           [-1, 2048, 8, 8]       2,097,152\n",
      "     BatchNorm2d-320           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-321           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-322           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-323            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-324            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-325            [-1, 512, 8, 8]               0\n",
      "          Conv2d-326            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-327            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-328            [-1, 512, 8, 8]               0\n",
      "          Conv2d-329           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-330           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-331           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-332           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-333            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-334            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-335            [-1, 512, 8, 8]               0\n",
      "          Conv2d-336            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-337            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-338            [-1, 512, 8, 8]               0\n",
      "          Conv2d-339           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-340           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-341           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-342           [-1, 2048, 8, 8]               0\n",
      "AdaptiveAvgPool2d-343         [-1, 2048, 14, 14]               0\n",
      "================================================================\n",
      "Total params: 42,500,160\n",
      "Trainable params: 42,274,816\n",
      "Non-trainable params: 225,344\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 564.31\n",
      "Params size (MB): 162.13\n",
      "Estimated Total Size (MB): 727.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "word_map = \"WORDMAP_coco_5_cap_per_img_5_min_word_freq.json\"\n",
    "model = \"BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar\"\n",
    "beam_size = 5\n",
    "device = 'cpu'\n",
    "\n",
    "checkpoint = torch.load(model, map_location=device)\n",
    "decoder = checkpoint['decoder']\n",
    "decoder = decoder.to(device)\n",
    "decoder.eval()\n",
    "encoder = checkpoint['encoder']\n",
    "encoder = encoder.to(device)\n",
    "#encoder.eval()\n",
    "summary(encoder, (3,256,256))\n",
    "# Load word map (word2ix)\n",
    "with open(word_map, 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "rev_word_map = {v: k for k, v in word_map.items()}  # ix2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (resnet): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(14, 14))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myencoder = Encoder()\n",
    "myencoder.eval()\n",
    "encoder = checkpoint['encoder']\n",
    "encoder = encoder.to(device)\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = encoder.state_dict()\n",
    "sd2 = myencoder.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weight'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = dict()\n",
    "# for key in sd.keys():\n",
    "#     param[key] = torch.Tensor(sd[key].shape)\n",
    "# for key in sd.keys():\n",
    "#     condition = (sd[key] == False)\n",
    "#     for i in list(condition.nonzero()):\n",
    "#         param[key][tuple(i)] = False\n",
    "# # print(param[tuple(i)].dtype)\n",
    "# # print(sd['resnet.0.weight'])\n",
    "# # index_list = condition.nonzero()\n",
    "# # print(index_list.shape)\n",
    "# # idd = tuple(index_list[0])\n",
    "# # print(sd['resnet.0.weight'][idd])\n",
    "# # print(sd['resnet.0.weight'][index_list[0]])\n",
    "# # print(sd['resnet.0.weight'][index_list[0]-[0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = torch.tensor([4,15,False])\n",
    "# c = A[2].type(torch.bool)\n",
    "# print(c.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps = 1e-4\n",
    "# for key in sd.keys():\n",
    "#     sd[key][abs(sd[key])<eps] = 0\n",
    "#     sd2[key] = sd[key].type(torch.float16)\n",
    "#     param[key] = torch.Tensor(sd[key].shape)\n",
    "#     sd[key][abs(sd[key])<eps] = False\n",
    "# for key in sd.keys():\n",
    "#     if len(sd[key].shape) == 4:\n",
    "#         for i in range(sd[key].shape[0]):\n",
    "#             for j in range(sd[key].shape[1]):\n",
    "#                 for k in range(sd[key].shape[2]):\n",
    "#                     for l in range(sd[key].shape[3]):\n",
    "#                         if sd[key][i,j,k,l] == 0:\n",
    "#                             param[key][i,j,k,l] = False\n",
    "#                         else:\n",
    "#                             param[key][i,j,k,l] = sd[key][i,j,k,l].type(torch.float16)\n",
    "#     else:\n",
    "#         param[key] = sd[key].type(torch.float16)\n",
    "#     \n",
    "#     sd[key][abs(sd[key])==False]\n",
    "#     sd2[key] = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '_forward_pre_hooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10480/3236511959.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'weight'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mpruner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln_structured\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mamount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0msd2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpruner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mpruner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msd2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\prune.py\u001b[0m in \u001b[0;36mln_structured\u001b[1;34m(module, name, amount, n, dim, importance_scores)\u001b[0m\n\u001b[0;32m   1003\u001b[0m             )\n\u001b[0;32m   1004\u001b[0m     \"\"\"\n\u001b[1;32m-> 1005\u001b[1;33m     LnStructured.apply(\n\u001b[0m\u001b[0;32m   1006\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportance_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m     )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\prune.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(cls, module, name, amount, n, dim, importance_scores)\u001b[0m\n\u001b[0;32m    784\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0munspecified\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mits\u001b[0m \u001b[0mplace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \"\"\"\n\u001b[1;32m--> 786\u001b[1;33m         return super(LnStructured, cls).apply(\n\u001b[0m\u001b[0;32m    787\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\prune.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(cls, module, name, importance_scores, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_composite_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;31m# at this point we have no forward_pre_hooks but we could have an\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;31m# active reparametrization of the tensor if another pruning method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\prune.py\u001b[0m in \u001b[0;36m_get_composite_method\u001b[1;34m(cls, module, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;31m# assert this using `found`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mhooks_to_remove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m                 \u001b[1;31m# if it exists, take existing thing, remove hook, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[1;31m# go through normal thing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '_forward_pre_hooks'"
     ]
    }
   ],
   "source": [
    "# for key in sd.keys():\n",
    "#     if 'weight' in key:\n",
    "#         pruner = prune.ln_structured(sd[key], name='weight',amount=0.1, n=2,dim=0)\n",
    "#         sd2[key] = pruner.prune(sd[key])\n",
    "#         pruner.remove(sd2[key], 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summ = 0\n",
    "# for key in sd2.keys():\n",
    "#     condition = sd2[key]== 0\n",
    "#     summ += len(list(condition.nonzero()))\n",
    "#     print(key, ' has :', len(list(condition.nonzero())), 'zeroes')\n",
    "# print('total zeroes deducted: ', summ)\n",
    "# print(sd2['resnet.0.weight'])\n",
    "# print(sd2['resnet.0.weight'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myencoder.load_state_dict(sd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(myencoder, (3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = 0\n",
    "for name, param in myencoder.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(len(param[param!=dict(encoder.named_parameters())[name.split('_')[0]]]))\n",
    "        summ +=len(param[param!=dict(encoder.named_parameters())[name.split('_')[0]]])\n",
    "print(summ)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(myencoder, (3,256,256))\n",
    "summary(encoder, (3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sd)\n",
    "# print(sd.keys())\n",
    "# print(\"\\nNEW ENCODER\\n\")\n",
    "# print(sd2.keys())\n",
    "# for key in sd.keys():\n",
    "#     if key not in sd2.keys():\n",
    "#         print('They are not the same')\n",
    "# print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = r\"C:\\Users\\xiaomi\\OneDrive\\TUM\\WS 2021-2022\\Advanced Topics in Communication Electronics\\image-captioning-on-pytorch-master\\image-captioning-on-pytorch-master\\img5.jpg\"\n",
    "seq, alphas = caption.caption_image_beam_search(myencoder, decoder, img, word_map, beam_size)\n",
    "seq_orig, alphas_orig = caption.caption_image_beam_search(encoder, decoder, img, word_map, beam_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = torch.FloatTensor(alphas)\n",
    "alphas_orig = torch.FloatTensor(alphas_orig)\n",
    "words = [rev_word_map[ind] for ind in seq]\n",
    "words_orig = [rev_word_map[ind] for ind in seq_orig]\n",
    "sentence = \"\"\n",
    "sentence_orig = \"\"\n",
    "for word in words:\n",
    "    sentence = sentence + \" \" + word\n",
    "for word in words_orig:\n",
    "    sentence_orig = sentence_orig + \" \" + word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence)\n",
    "print(sentence_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = prune.L1Unstructured(amount=0.7)\n",
    "for name, module in myencoder.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.random_unstructured(module, name='weight', amount=0.3)\n",
    "        print(\"salam\")\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        print(\"linear\")\n",
    "# myencoder.resnet[0].weight_orig\n",
    "pruned_tensor = pruner.prune(tensor)\n",
    "print(myencoder.resnet[0].weight_mask)\n",
    "torch.mul(myencoder.resnet[0].weight_orig,myencoder.resnet[0].weight_mask )               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(encoder.resnet[0].weight[0,0,0,0].dtype)\n",
    "# print(encoder.resnet[1])\n",
    "# print(encoder.resnet[2])\n",
    "# print(encoder.resnet[3])\n",
    "# print(encoder.resnet[4])\n",
    "# print(encoder.resnet[5])\n",
    "# print(encoder.resnet[6])\n",
    "# print(encoder.resnet[7])\n",
    "# for name, module in myencoder.named_modules():\n",
    "#     print('Name:',name)#, 'Module:\\n',module)\n",
    "# #     print(module.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in myencoder.named_parameters():\n",
    "    print('Name:',name, 'Parameter:\\n', param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(myencoder.named_parameters())['resnet.0.weight_orig'])\n",
    "print(dict(myencoder.named_parameters())['resnet.0.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "224556cf7c5c9b055ae49a6675c30d5f2054c9ee267b704439a1be7caf4d323c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
